{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:18:37.138184Z",
     "start_time": "2024-01-11T02:18:36.308070Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train= False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "learning_rate =1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:19:07.984997Z",
     "start_time": "2024-01-11T02:19:07.981526Z"
    }
   },
   "id": "a5a71ea87806ac64",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:21:05.550968Z",
     "start_time": "2024-01-11T02:21:05.544399Z"
    }
   },
   "id": "dfe8c49083aa2d7a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:25:12.335108Z",
     "start_time": "2024-01-11T02:25:12.322150Z"
    }
   },
   "id": "7ccb0f2568e10825",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:25:13.225905Z",
     "start_time": "2024-01-11T02:25:13.219316Z"
    }
   },
   "id": "1408d8f6edf2c36f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309604  [   64/60000]\n",
      "loss: 2.291197  [ 6464/60000]\n",
      "loss: 2.272173  [12864/60000]\n",
      "loss: 2.259893  [19264/60000]\n",
      "loss: 2.230398  [25664/60000]\n",
      "loss: 2.210742  [32064/60000]\n",
      "loss: 2.225853  [38464/60000]\n",
      "loss: 2.186698  [44864/60000]\n",
      "loss: 2.173594  [51264/60000]\n",
      "loss: 2.139097  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 2.139707 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.148560  [   64/60000]\n",
      "loss: 2.142079  [ 6464/60000]\n",
      "loss: 2.082522  [12864/60000]\n",
      "loss: 2.101881  [19264/60000]\n",
      "loss: 2.033279  [25664/60000]\n",
      "loss: 1.982239  [32064/60000]\n",
      "loss: 2.020083  [38464/60000]\n",
      "loss: 1.933199  [44864/60000]\n",
      "loss: 1.926446  [51264/60000]\n",
      "loss: 1.865647  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 1.862114 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.889396  [   64/60000]\n",
      "loss: 1.865584  [ 6464/60000]\n",
      "loss: 1.745624  [12864/60000]\n",
      "loss: 1.795562  [19264/60000]\n",
      "loss: 1.662280  [25664/60000]\n",
      "loss: 1.628302  [32064/60000]\n",
      "loss: 1.654623  [38464/60000]\n",
      "loss: 1.550996  [44864/60000]\n",
      "loss: 1.564602  [51264/60000]\n",
      "loss: 1.474410  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.491250 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.552923  [   64/60000]\n",
      "loss: 1.525475  [ 6464/60000]\n",
      "loss: 1.374798  [12864/60000]\n",
      "loss: 1.455326  [19264/60000]\n",
      "loss: 1.312910  [25664/60000]\n",
      "loss: 1.320849  [32064/60000]\n",
      "loss: 1.335038  [38464/60000]\n",
      "loss: 1.259121  [44864/60000]\n",
      "loss: 1.288419  [51264/60000]\n",
      "loss: 1.200041  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.227487 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.300815  [   64/60000]\n",
      "loss: 1.287969  [ 6464/60000]\n",
      "loss: 1.122257  [12864/60000]\n",
      "loss: 1.235127  [19264/60000]\n",
      "loss: 1.092911  [25664/60000]\n",
      "loss: 1.122397  [32064/60000]\n",
      "loss: 1.145274  [38464/60000]\n",
      "loss: 1.082107  [44864/60000]\n",
      "loss: 1.119298  [51264/60000]\n",
      "loss: 1.046196  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.066695 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.135864  [   64/60000]\n",
      "loss: 1.141669  [ 6464/60000]\n",
      "loss: 0.956553  [12864/60000]\n",
      "loss: 1.098892  [19264/60000]\n",
      "loss: 0.961814  [25664/60000]\n",
      "loss: 0.991486  [32064/60000]\n",
      "loss: 1.033027  [38464/60000]\n",
      "loss: 0.973027  [44864/60000]\n",
      "loss: 1.011422  [51264/60000]\n",
      "loss: 0.953067  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.965145 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.023874  [   64/60000]\n",
      "loss: 1.049384  [ 6464/60000]\n",
      "loss: 0.844447  [12864/60000]\n",
      "loss: 1.009718  [19264/60000]\n",
      "loss: 0.880693  [25664/60000]\n",
      "loss: 0.901353  [32064/60000]\n",
      "loss: 0.961414  [38464/60000]\n",
      "loss: 0.903366  [44864/60000]\n",
      "loss: 0.938230  [51264/60000]\n",
      "loss: 0.891350  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.896729 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.942332  [   64/60000]\n",
      "loss: 0.985943  [ 6464/60000]\n",
      "loss: 0.764644  [12864/60000]\n",
      "loss: 0.947194  [19264/60000]\n",
      "loss: 0.826353  [25664/60000]\n",
      "loss: 0.836594  [32064/60000]\n",
      "loss: 0.911306  [38464/60000]\n",
      "loss: 0.857167  [44864/60000]\n",
      "loss: 0.885861  [51264/60000]\n",
      "loss: 0.846920  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.847640 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.879874  [   64/60000]\n",
      "loss: 0.938410  [ 6464/60000]\n",
      "loss: 0.705218  [12864/60000]\n",
      "loss: 0.900763  [19264/60000]\n",
      "loss: 0.787227  [25664/60000]\n",
      "loss: 0.788420  [32064/60000]\n",
      "loss: 0.872896  [38464/60000]\n",
      "loss: 0.824825  [44864/60000]\n",
      "loss: 0.846671  [51264/60000]\n",
      "loss: 0.812790  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.810307 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.829740  [   64/60000]\n",
      "loss: 0.899961  [ 6464/60000]\n",
      "loss: 0.659164  [12864/60000]\n",
      "loss: 0.864689  [19264/60000]\n",
      "loss: 0.757125  [25664/60000]\n",
      "loss: 0.751653  [32064/60000]\n",
      "loss: 0.841554  [38464/60000]\n",
      "loss: 0.800738  [44864/60000]\n",
      "loss: 0.816003  [51264/60000]\n",
      "loss: 0.785202  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.780340 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T02:27:00.235181Z",
     "start_time": "2024-01-11T02:25:18.934366Z"
    }
   },
   "id": "e8346b31489fff30",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e9d2db92c7abd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torchstudy",
   "language": "python",
   "display_name": "torchStudy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## nn.Module vs. nn.Sequential\n",
    "nn.Module은 딥러닝에 사용되는 모든 파라미터가 저장되어 있고 자신이 원하는 대로 신경망 동작 정의 가능\n",
    "nn.Sequential은 층을 쌓기만 하는 간단한 구조에 사용하기 편리 그러나 은닉층에서 순전파 도중의\n",
    "결과를 저장한다거나 데이터 흐름을 제어하는 등의 커스터마이징 불가능"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1176c012d33d734"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_dim):\n",
    "        #자식 클래스가 상속받은 부모 클래스를 자식클래스에 불러오겠다 \n",
    "        #super().__init__()과 차이 없음 현재 사용하는 클래스가 무엇인지 알려주는 용도임 \n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        #합성곱층 정의\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, out_channels,kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T04:58:35.416478Z",
     "start_time": "2024-01-10T04:58:34.902331Z"
    }
   },
   "id": "dffb358c7d471b68",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "합성곱을 하여 나온 이미지를 평탄화(1차원 벡터로 변환)\n",
    "MLP층은 벡터만을 입력으로 받을 수 있기 때문에 이 작업이 필요\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b26a2a1438d2939"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 합성곱 기본 블록 정의\n",
    "        self.block1 = BasicBlock(in_channels=3, out_channels=32, hidden_dim=16)\n",
    "        self.block2 = BasicBlock(in_channels=32, out_channels=128, hidden_dim=64)\n",
    "        self.block3 = BasicBlock(in_channels=128, out_channels=256, hidden_dim=128)\n",
    "        \n",
    "        # 분류기 정의\n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T05:03:56.341804Z",
     "start_time": "2024-01-10T05:03:56.338001Z"
    }
   },
   "id": "fdfb60056a0d0b48",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/ws/lngrb3y14bx9ckr9196sk6qm0000gn/T/ipykernel_45615/20704110.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     45\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m%\u001B[0m\u001B[0;36m10\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m9\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    151\u001B[0m                    \u001B[0mweight_decay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'weight_decay'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m                    \u001B[0meps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'eps'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m                    maximize=group['maximize'])\n\u001B[0m\u001B[1;32m    154\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/optim/_functional.py\u001B[0m in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m         \u001B[0mstep_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbias_correction1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 110\u001B[0;31m         \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddcdiv_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexp_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdenom\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mstep_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    111\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m def adamw(params: List[Tensor],\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import RandomHorizontalFlip, ToTensor, Normalize\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import RandomCrop\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "transforms = Compose([\n",
    "    RandomCrop((32,32), padding=4), #랜덤 크롭핑\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=(0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "training_data = CIFAR10(\n",
    "    root=\"./\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root=\"./\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN(num_classes=10).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for data, label in train_loader:\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        preds = model(data.to(device))\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    if epoch == 0 or epoch%10 == 9:\n",
    "        print(f\"epoch{epoch+1} loss:{loss.item()}\")\n",
    "        \n",
    "torch.save(model.state_dict(),\"CIFAR.pth\")\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T05:18:29.600999Z",
     "start_time": "2024-01-10T05:18:01.182705Z"
    }
   },
   "id": "734f44b4420f261",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CIFAR.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/ws/lngrb3y14bx9ckr9196sk6qm0000gn/T/ipykernel_45615/1959074167.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#모델 성능 평가하기\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"CIFAR.pth\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mnum_corr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    697\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    230\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 231\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    232\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/torchStudy/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'CIFAR.pth'"
     ]
    }
   ],
   "source": [
    "#모델 성능 평가하기\n",
    "model.load_state_dict(torch.load(\"CIFAR.pth\", map_location=device))\n",
    "\n",
    "num_corr = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        \n",
    "        output = model(data.to(device))\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label.to(device).data).sum().item()\n",
    "        num_corr += corr\n",
    "        \n",
    "    print(f\"Accuracy: {num_corr/len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T05:20:36.054077Z",
     "start_time": "2024-01-10T05:20:35.998115Z"
    }
   },
   "id": "c478df3e3e553504",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "이미지 개수가 많을 수록 더 오랜 학습시간이 필요 \n",
    "데이터가 달라질 때마다 매번 새로 학습해야 할까? \n",
    "## 전이학습\n",
    "다른 데이터를 이용해 학습된 모델을 갖고 있는 데이터에 최적화 시키는 학습 방법\n",
    "읿반적으로 대용량 데이터를 이요해 사전 학습한 모델을 소규모 데이터에 최적화 시킨다"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16ce9bd301abf69e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb3e0891b7bd40e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torchstudy",
   "language": "python",
   "display_name": "torchStudy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
